{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "689f9c78",
   "metadata": {},
   "source": [
    "### Softmax Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a58d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z))\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5673a8b",
   "metadata": {},
   "source": [
    "![alt text](<สกรีนช็อต 2025-12-25 132925.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32856c",
   "metadata": {},
   "source": [
    "### Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "383edb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(predicted, actual):\n",
    "    m = actual.shape[0]\n",
    "    log_likehood = -np.log(predicted[range(m), actual])\n",
    "    loss = np.sum(log_likehood) / m\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b82c41",
   "metadata": {},
   "source": [
    "![alt text](<สกรีนช็อต 2025-12-25 133018.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d242e5d",
   "metadata": {},
   "source": [
    "### Softmax Classifier (Training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6642047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxClassifier:\n",
    "    def __init__(self, learning_rate=0.01, num_classes=3, num_features=2):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.random.randn(num_features, num_classes)\n",
    "        self.bias = np.zeros((1, num_classes))\n",
    "\n",
    "    def train(self, X, y, epochs=1000):\n",
    "        for epoch in range(epochs):\n",
    "            # Forward pass\n",
    "            logits = np.dot(X, self.weights) + self.bias\n",
    "            probabilities = softmax(logits)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = cross_entropy_loss(probabilities, y)\n",
    "\n",
    "            # Backward pass (Gradient Descent)\n",
    "            m = X.shape[0]\n",
    "            grad_logits = probabilities\n",
    "            grad_logits[range(m), y] -= 1   # Gradient of Loss with respect to Logits\n",
    "\n",
    "            grad_logits /= m\n",
    "\n",
    "            # Update weights and bias\n",
    "            self.weights -= self.learning_rate * np.dot(X.T, grad_logits)\n",
    "            self.bias -= self.learning_rate * np.sum(grad_logits, axis=0,\n",
    "                                                     keepdims=True)\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch} - Loss: {loss}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        logits = np.dot(X, self.weights) + self.bias\n",
    "        probabilities = softmax(logits)\n",
    "        return np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b5b02",
   "metadata": {},
   "source": [
    "![alt text](<สกรีนช็อต 2025-12-26 010416.png>)\n",
    "![alt text](<สกรีนช็อต 2025-12-26 010611.png>)\n",
    "![alt text](<สกรีนช็อต 2025-12-26 010653.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c67764",
   "metadata": {},
   "source": [
    "### Sample dataset (X: input features, y: class labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e7d104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 3.7104452730315565\n",
      "Epoch 100 - Loss: 1.0279163964969993\n",
      "Epoch 200 - Loss: 0.933955209176888\n",
      "Epoch 300 - Loss: 0.8599934147977155\n",
      "Epoch 400 - Loss: 0.7999937373145256\n",
      "Epoch 500 - Loss: 0.7504714012658961\n",
      "Epoch 600 - Loss: 0.7088831368134024\n",
      "Epoch 700 - Loss: 0.6733846651903096\n",
      "Epoch 800 - Loss: 0.6426333346450385\n",
      "Epoch 900 - Loss: 0.6156418870978839\n",
      "Predictions: [0 0 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2], [2, 1], [3, 1], [1, 3], [2, 3], [3, 2]])\n",
    "y = np.array([0, 0, 1, 1, 2, 2])    # classes\n",
    "\n",
    "# Initialize and train the classifier\n",
    "classifier = SoftmaxClassifier(learning_rate=0.1, num_classes=3,\n",
    "                               num_features=2)\n",
    "classifier.train(X, y, epochs=1000)\n",
    "\n",
    "# Predict\n",
    "predictions = classifier.predict(X)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6866da3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
